{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download el_core_news_sm\r\n",
        "#!pip install pyarrow --upgrade"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272907574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import el_core_news_sm\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1614326239131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import GreekLemmatizer"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1614272908948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1614272909098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = el_core_news_sm.load()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1614272909315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = GreekLemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1614272909406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = re.compile('δεν απαντ.{1,3}\\s{0,1}',re.IGNORECASE)\r\n",
        "p2 = re.compile('\\sδα\\s',re.IGNORECASE)\r\n",
        "p3 = re.compile('δε.{0,1}\\s.{0,3}\\s{0,1}βρ.{1,2}κ.\\s{0,1}',re.IGNORECASE)\r\n",
        "p4 = re.compile('[^\\d]?\\d{10}')\r\n",
        "p5 = re.compile('[^\\d]?\\d{18}|[^\\d]\\d{20}')\r\n",
        "p6 = re.compile('δε[ ν]{0,1} (επιθυμ[α-ω]{2,4}?|ηθελ[α-ω]{1,3}?|θελ[α-ω]{1,4}|.{0,10}ενδιαφερ[α-ω]{2,4})',re.IGNORECASE)\r\n",
        "p7 = re.compile('δε[ ν]{0,1} (μπορ[α-ω]{2,5}|.εχει)',re.IGNORECASE)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272909493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadStopWords():\n",
        "    sWords = open('stopWords.txt','r',encoding='utf-8')\n",
        "    sw = set(sWords.read().split('\\n'))\n",
        "    #sw = sw.remove('μη')\n",
        "    sWords.close()\n",
        "    return sw"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1614272909584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTerm(text):\r\n",
        "    text = p5.sub(' λογαριασμός ',text)\r\n",
        "    text = p4.sub(' τηλεφωνο ',text)\r\n",
        "    text = p6.sub(' δενθελειδενενδιαφερεται ',text)\r\n",
        "    text = p7.sub(' δενεχειδενμπορει ',text)\r\n",
        "    text = text.replace('-banking','banking')\r\n",
        "    text = text.replace('v banking','vbanking')\r\n",
        "    text = text.replace('e banking','ebanking')\r\n",
        "    text = text.replace('follow up','followup')\r\n",
        "    text = text.replace('safe drive','safedrive')\r\n",
        "    text = text.replace('safe pocket','safepocket')\r\n",
        "    text = text.replace('sweet home','sweethome')\r\n",
        "    text = text.replace('credit card','creditcard')\r\n",
        "    text = text.replace('debit card','debitcard')\r\n",
        "    text = text.replace('life cycle','lifecycle')\r\n",
        "    text = text.replace('π/κ','πκ')\r\n",
        "    text = text.replace('α/κ','ακ')\r\n",
        "    text = text.replace('δ/α','δεναπαντα ')\r\n",
        "    #τδ\r\n",
        "    text = p1.sub(' δεναπαντα ',text)\r\n",
        "    text = p2.sub(' δεναπαντα ',text)\r\n",
        "    text = p3.sub(' δεντονβρηκα ',text)\r\n",
        "    return text\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272909799
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sw = nlp.Defaults.stop_words\n",
        "#sw = sw|{'εχω','απο','ωστε'}\n",
        "sw = loadStopWords()\n",
        "def remove_ton(text):\n",
        "    diction = {'ά':'α','έ':'ε','ί':'ι','ό':'ο','ώ':'ω','ύ':'υ'}\n",
        "    for key in diction.keys():\n",
        "        text = text.replace(key, diction[key])\n",
        "    return text   \n",
        "def clean_text(text):\n",
        "     #text to string\n",
        "    text = str(text).lower()\n",
        "    text = replaceTerm(text)\n",
        "   # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # lower text\n",
        "    text = [remove_ton(x) for x in text]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in sw]\n",
        " \n",
        "    #remove quotes\n",
        "    text = [x.replace('quot;','').replace('&quot','') for x in text if x not in ['quot','amp']]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # remove amp & quot\n",
        "    text = [x for x in text if x not in ['quot','amp']]\n",
        "    # remove words with only one letter\n",
        "    text = \" \".join([t for t in text if len(t) > 1])\n",
        "    # lemmatize text\n",
        "    text = \" \".join([lemmatizer(t.text,t.pos_)[0] for t in nlp(text)])\n",
        "   \n",
        "    return(text)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1614272909905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(x,corDict):\r\n",
        "    if x in corDict.keys():\r\n",
        "        y = corDict[x]\r\n",
        "    else:\r\n",
        "        y = x\r\n",
        "    return y    "
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272910010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileNum = '12'"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272910101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\n",
        "resource_group = 'MLRG'\n",
        "workspace_name = 'erbbimlws'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='LinkComments{0}'.format(fileNum))\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1614272916150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['CON_ROW_ID','CON_COMMENTS']]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1614272916337
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.columns\r\n",
        "df.head()\r\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "(140931, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614272916539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'] = df['CON_COMMENTS'].apply(clean_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1614274168521
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_excel('LinkCommentssample_2.xlsx')\r\n",
        "#df.head(1000)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1614274168636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1614274168795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df[df['tokenized'].str.contains(' χρονι ') ]#[~df['tokenized'].str.contains('banking') ]"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274168886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(min_df = 1000,ngram_range = (1,2))"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1614274168979
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_result = tfidf.fit_transform(df['tokenized']).toarray()"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1614274171693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1614274171787
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.columns = [str(x) for x in tfidf_df.columns]"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1614274171879
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = pd.concat([df[['CON_ROW_ID']],tfidf_df],axis=1).melt(id_vars=['CON_ROW_ID'],value_vars = tfidf_df.columns).dropna()"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1614274174829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['value']>0]"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1614274174936
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "(273322, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['variable'].value_counts().to_excel('tokenlist.xlsx')"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corDict = dict(pd.read_excel(\"corTokens.xls\").to_dict(\"split\")['data'])"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token'] = df_f['variable'].apply(lambda x : correct(x,corDict))"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['token'] !='rmv']"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.sort_values(['CON_ROW_ID','token'])"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175752
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token_c'] = df_f['token']"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = df_f.shape[0]"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274175932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.head(100)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "          CON_ROW_ID    variable     value              token  \\\n3100484   60373305.0   ασφαλειας  0.806004           ασφαλεια   \n9442379   60373305.0        ληξη  0.591911               ληξη   \n1127451   60995338.0        visa  0.751607               visa   \n7187486   62513965.0       ευχες  0.714282              ευχες   \n12401933  62513965.0  προγραμμας  0.699858          προγραμμα   \n...              ...         ...       ...                ...   \n9442411   62736090.0        ληξη  1.000000               ληξη   \n1973069   62737213.0          ακ  0.317030  αμοιβαιο κεφαλαιο   \n2395862   62737213.0    ανανεωση  0.289387           ανανεωση   \n4932620   62737213.0    εκκινηση  0.317247           εκκινηση   \n7046585   62737213.0        ευρω  0.328910               ευρω   \n\n                    token_c  \n3100484            ασφαλεια  \n9442379                ληξη  \n1127451                visa  \n7187486               ευχες  \n12401933          προγραμμα  \n...                     ...  \n9442411                ληξη  \n1973069   αμοιβαιο κεφαλαιο  \n2395862            ανανεωση  \n4932620            εκκινηση  \n7046585                ευρω  \n\n[100 rows x 5 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CON_ROW_ID</th>\n      <th>variable</th>\n      <th>value</th>\n      <th>token</th>\n      <th>token_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3100484</th>\n      <td>60373305.0</td>\n      <td>ασφαλειας</td>\n      <td>0.806004</td>\n      <td>ασφαλεια</td>\n      <td>ασφαλεια</td>\n    </tr>\n    <tr>\n      <th>9442379</th>\n      <td>60373305.0</td>\n      <td>ληξη</td>\n      <td>0.591911</td>\n      <td>ληξη</td>\n      <td>ληξη</td>\n    </tr>\n    <tr>\n      <th>1127451</th>\n      <td>60995338.0</td>\n      <td>visa</td>\n      <td>0.751607</td>\n      <td>visa</td>\n      <td>visa</td>\n    </tr>\n    <tr>\n      <th>7187486</th>\n      <td>62513965.0</td>\n      <td>ευχες</td>\n      <td>0.714282</td>\n      <td>ευχες</td>\n      <td>ευχες</td>\n    </tr>\n    <tr>\n      <th>12401933</th>\n      <td>62513965.0</td>\n      <td>προγραμμας</td>\n      <td>0.699858</td>\n      <td>προγραμμα</td>\n      <td>προγραμμα</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9442411</th>\n      <td>62736090.0</td>\n      <td>ληξη</td>\n      <td>1.000000</td>\n      <td>ληξη</td>\n      <td>ληξη</td>\n    </tr>\n    <tr>\n      <th>1973069</th>\n      <td>62737213.0</td>\n      <td>ακ</td>\n      <td>0.317030</td>\n      <td>αμοιβαιο κεφαλαιο</td>\n      <td>αμοιβαιο κεφαλαιο</td>\n    </tr>\n    <tr>\n      <th>2395862</th>\n      <td>62737213.0</td>\n      <td>ανανεωση</td>\n      <td>0.289387</td>\n      <td>ανανεωση</td>\n      <td>ανανεωση</td>\n    </tr>\n    <tr>\n      <th>4932620</th>\n      <td>62737213.0</td>\n      <td>εκκινηση</td>\n      <td>0.317247</td>\n      <td>εκκινηση</td>\n      <td>εκκινηση</td>\n    </tr>\n    <tr>\n      <th>7046585</th>\n      <td>62737213.0</td>\n      <td>ευρω</td>\n      <td>0.328910</td>\n      <td>ευρω</td>\n      <td>ευρω</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274176042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(0,n-1):\r\n",
        "#    if df_f['CON_ROW_ID'].iloc[i] == df_f['CON_ROW_ID'].iloc[i+1]:\r\n",
        "#        #print(df_f['token_c'].iloc[i],type(df_f['token_c'].iloc[i]),type(df_f['token_c'].iloc[i+1]),df_f['token_c'].iloc[i+1])\r\n",
        "#        if df_f['token_c'].iloc[i] in df_f['token_c'].iloc[i+1]:\r\n",
        "#            df_f.iloc[i,4] = df_f['token_c'].iloc[i+1]\r\n",
        "        \r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274176130
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[['CON_ROW_ID','token_c']].drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274176226
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f.head()\r\n",
        "#df_f.shape\r\n",
        "#df_f['token_c'].value_counts().to_excel('tokens_c.xlsx')"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274176314
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.to_csv('comments_tokens_{0}.txt'.format(fileNum),sep ='\\t',line_terminator='\\r\\n',index = False)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274176899
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f.to_excel('vBanking_tokens_s.xlsx',index = False)\n",
        "#df_f[df_f['value']>0].to_excel('D://Downloads//comments_tokens.xlsx')\n",
        "#df.to_excel('D://Downloads//comments_cleaned.xlsx')"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1614274176988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f[df_f['CON_ROW_ID'] ==60427536]\r\n"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614274177132
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}