{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download el_core_news_sm\r\n",
        "#!pip install pyarrow --upgrade"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614169630963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import el_core_news_sm\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1614169632283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import GreekLemmatizer"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1614169632697
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1614169632972
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = el_core_news_sm.load()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1614169633285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = GreekLemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1614169633381
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = re.compile('δεν απαντ.{1,3}\\s{0,1}',re.IGNORECASE)\r\n",
        "p2 = re.compile('\\sδα\\s',re.IGNORECASE)\r\n",
        "p3 = re.compile('δε.{0,1}\\s.{0,3}\\s{0,1}βρ.{1,2}κ.\\s{0,1}',re.IGNORECASE)\r\n",
        "p4 = re.compile('[^\\d]?\\d{10}')\r\n",
        "p5 = re.compile('[^\\d]?\\d{18}|[^\\d]\\d{20}')\r\n",
        "p6 = re.compile('δε[ ν] {0,1} (επιθυμ[α-ω]{2,4}?|ηθελ[α-ω]{1,3}?|θελ[α-ω]{1,4}|.{0,10}ενδιαφερ[α-ω]{2,4})',re.IGNORECASE)\r\n",
        "p7 = re.compile('δε[ ν] {0,1} (μπορ[α-ω]{2,5}|.εχει)',re.IGNORECASE)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614169633476
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadStopWords():\n",
        "    sWords = open('stopWords.txt','r',encoding='utf-8')\n",
        "    sw = set(sWords.read().split('\\n'))\n",
        "    #sw = sw.remove('μη')\n",
        "    sWords.close()\n",
        "    return sw"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1614169633783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTerm(text):\r\n",
        "    text = p5.sub(' λογαριασμός ',text)\r\n",
        "    text = p4.sub(' τηλεφωνο ',text)\r\n",
        "    text = p6.sub(' δενθελειδενενδιαφερεται ',text)\r\n",
        "    text = p7.sub(' δενεχειδενμπορει ',text)\r\n",
        "    text = text.replace('-banking','banking')\r\n",
        "    text = text.replace('v banking','vbanking')\r\n",
        "    text = text.replace('e banking','ebanking')\r\n",
        "    text = text.replace('follow up','followup')\r\n",
        "    text = text.replace('safe drive','safedrive')\r\n",
        "    text = text.replace('safe pocket','safepocket')\r\n",
        "    text = text.replace('sweet home','sweethome')\r\n",
        "    text = text.replace('credit card','creditcard')\r\n",
        "    text = text.replace('debit card','debitcard')\r\n",
        "    text = text.replace('life cycle','lifecycle')\r\n",
        "    text = text.replace('π/κ','πκ')\r\n",
        "    text = text.replace('α/κ','ακ')\r\n",
        "    text = text.replace('δ/α','δεναπαντα ')\r\n",
        "    text = p1.sub(' δεναπαντα ',text)\r\n",
        "    text = p2.sub(' δεναπαντα ',text)\r\n",
        "    text = p3.sub(' δεντονβρηκα ',text)\r\n",
        "    return text\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614169633880
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sw = nlp.Defaults.stop_words\n",
        "#sw = sw|{'εχω','απο','ωστε'}\n",
        "sw = loadStopWords()\n",
        "def remove_ton(text):\n",
        "    diction = {'ά':'α','έ':'ε','ί':'ι','ό':'ο','ώ':'ω','ύ':'υ'}\n",
        "    for key in diction.keys():\n",
        "        text = text.replace(key, diction[key])\n",
        "    return text   \n",
        "def clean_text(text):\n",
        "     #text to string\n",
        "    text = str(text).lower()\n",
        "    text = replaceTerm(text)\n",
        "   # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # lower text\n",
        "    text = [remove_ton(x) for x in text]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in sw]\n",
        " \n",
        "    #remove quotes\n",
        "    text = [x.replace('quot;','').replace('&quot','') for x in text if x not in ['quot','amp']]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # remove amp & quot\n",
        "    text = [x for x in text if x not in ['quot','amp']]\n",
        "    # remove words with only one letter\n",
        "    text = \" \".join([t for t in text if len(t) > 1])\n",
        "    # lemmatize text\n",
        "    text = \" \".join([lemmatizer(t.text,t.pos_)[0] for t in nlp(text)])\n",
        "   \n",
        "    return(text)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1614169634115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(x,corDict):\r\n",
        "    if x in corDict.keys():\r\n",
        "        y = corDict[x]\r\n",
        "    else:\r\n",
        "        y = x\r\n",
        "    return y    "
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614169634219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\n",
        "resource_group = 'MLRG'\n",
        "workspace_name = 'erbbimlws'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='LinkCommentsSample')\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1614169640005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['CON_ROW_ID','CON_COMMENTS']]"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1614169640213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.columns\r\n",
        "df.head()\r\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "(188199, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614169640480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'] = df['CON_COMMENTS'].apply(clean_text)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1614171309351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_excel('LinkCommentssample_2.xlsx')\r\n",
        "df.head(1000)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "     CON_ROW_ID                                       CON_COMMENTS  \\\n0     4829747.0                                             LISTA2   \n1    54042370.0  Για την λήξη των 2 Value της ίδιας και των 3 V...   \n2    54042444.0  Για την λήξη των 3 Value της ίδιας και των 2 V...   \n3    54154396.0  ΛΗΞΗ ΠΥΡΑΣΦΑΛΙΣΤΗΡΙΟΥ 13/02/2019 ΤΗΛ ΓΙΑ ΝΑ ΚΑ...   \n4    55574534.0  ΤΟΠΟΘΕΤΗΣΗ ΣΕ Α/Κ ΚΑΙ ΕΚΤΑΚΤΗ ΚΑΤΑΒΟΛΗ ΣΤΟ ΤΑΚ...   \n..          ...                                                ...   \n995  62888661.0                   οκ θα ερθει την επομενη εβδομαδα   \n996  62888688.0  ΕΝΗΜΕΡΩΘΗΚΕ ΓΙΑ ΤΗΝ ΛΗΞΗ ΤΗΣ ΠΚ.ΕΙΝΑΙ ΣΤΗΝ ΕΠΑ...   \n997  62888694.0                              safe pocket ΝΕΧΤ ΤΙΜΕ   \n998  62888695.0         ΕΠΙΚΟΙΝΩΝΙΑ ΑΠΟ ΚΑΤΑΣΤΗΜΑ ΕΞΥΠΗΡΕΤΗΣΗΣ 164   \n999  62888720.0  ΤΗΛ ΕΠΙΚΟΙΝΩΝΙΑ ΤΗΝ ΤΡΙΤΗ ΓΙΑ ΕΠΙΒΕΒΑΙΩΣΗ ΡΑΝΤ...   \n\n                                             tokenized  \n0                                                       \n1                        λήξη value value κορης μαριας  \n2                              λήξη value value μητερα  \n3               ληξη πυρασφαλιστηριος τηλ κανω προταση  \n4                 τοποθετηση ακ εκτακτη καταβολη τακτο  \n..                                                 ...  \n995                          οκ ερθω επομενη εβδομαδος  \n996  ενημερωθηκε ληξη πκ.ειναι επαρχιο θελω τηλ ανα...  \n997                               safepocket νεχτ τιμε  \n998                επικοινωνιας καταστημας εξυπηρετηση  \n999  τηλ επικοινωνιας τριτη επιβεβαιωση ραντεβο τετ...  \n\n[1000 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CON_ROW_ID</th>\n      <th>CON_COMMENTS</th>\n      <th>tokenized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4829747.0</td>\n      <td>LISTA2</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54042370.0</td>\n      <td>Για την λήξη των 2 Value της ίδιας και των 3 V...</td>\n      <td>λήξη value value κορης μαριας</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54042444.0</td>\n      <td>Για την λήξη των 3 Value της ίδιας και των 2 V...</td>\n      <td>λήξη value value μητερα</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54154396.0</td>\n      <td>ΛΗΞΗ ΠΥΡΑΣΦΑΛΙΣΤΗΡΙΟΥ 13/02/2019 ΤΗΛ ΓΙΑ ΝΑ ΚΑ...</td>\n      <td>ληξη πυρασφαλιστηριος τηλ κανω προταση</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55574534.0</td>\n      <td>ΤΟΠΟΘΕΤΗΣΗ ΣΕ Α/Κ ΚΑΙ ΕΚΤΑΚΤΗ ΚΑΤΑΒΟΛΗ ΣΤΟ ΤΑΚ...</td>\n      <td>τοποθετηση ακ εκτακτη καταβολη τακτο</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>62888661.0</td>\n      <td>οκ θα ερθει την επομενη εβδομαδα</td>\n      <td>οκ ερθω επομενη εβδομαδος</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>62888688.0</td>\n      <td>ΕΝΗΜΕΡΩΘΗΚΕ ΓΙΑ ΤΗΝ ΛΗΞΗ ΤΗΣ ΠΚ.ΕΙΝΑΙ ΣΤΗΝ ΕΠΑ...</td>\n      <td>ενημερωθηκε ληξη πκ.ειναι επαρχιο θελω τηλ ανα...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>62888694.0</td>\n      <td>safe pocket ΝΕΧΤ ΤΙΜΕ</td>\n      <td>safepocket νεχτ τιμε</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>62888695.0</td>\n      <td>ΕΠΙΚΟΙΝΩΝΙΑ ΑΠΟ ΚΑΤΑΣΤΗΜΑ ΕΞΥΠΗΡΕΤΗΣΗΣ 164</td>\n      <td>επικοινωνιας καταστημας εξυπηρετηση</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>62888720.0</td>\n      <td>ΤΗΛ ΕΠΙΚΟΙΝΩΝΙΑ ΤΗΝ ΤΡΙΤΗ ΓΙΑ ΕΠΙΒΕΒΑΙΩΣΗ ΡΑΝΤ...</td>\n      <td>τηλ επικοινωνιας τριτη επιβεβαιωση ραντεβο τετ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1614171353223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614165664120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['tokenized'].str.contains(' χρονι ') ]#[~df['tokenized'].str.contains('banking') ]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614165664396
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(min_df = 500,ngram_range = (1,2))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614165664483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_result = tfidf.fit_transform(df['tokenized']).toarray()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614165669254
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614165669427
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.columns = [str(x) for x in tfidf_df.columns]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614165669604
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = pd.concat([df[['CON_ROW_ID']],tfidf_df],axis=1).melt(id_vars=['CON_ROW_ID'],value_vars = tfidf_df.columns).dropna()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1613129140232
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['value']>0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1613129207183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613129209958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['variable'].value_counts().to_excel('tokenlist.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613129215545
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corDict = dict(pd.read_excel(\"corTokens.xls\").to_dict(\"split\")['data'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130551249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token'] = df_f['variable'].apply(lambda x : correct(x,corDict))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130553976
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['token'] !='rmv']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130556553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130559728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.sort_values(['CON_ROW_ID','token'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130562719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token_c'] = df_f['token']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130565726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = df_f.shape[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130568079
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.head(100)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130570894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(0,n-1):\r\n",
        "#    if df_f['CON_ROW_ID'].iloc[i] == df_f['CON_ROW_ID'].iloc[i+1]:\r\n",
        "#        #print(df_f['token_c'].iloc[i],type(df_f['token_c'].iloc[i]),type(df_f['token_c'].iloc[i+1]),df_f['token_c'].iloc[i+1])\r\n",
        "#        if df_f['token_c'].iloc[i] in df_f['token_c'].iloc[i+1]:\r\n",
        "#            df_f.iloc[i,4] = df_f['token_c'].iloc[i+1]\r\n",
        "        \r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130632904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[['CON_ROW_ID','token_c']].drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130879788
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.head()\r\n",
        "df_f.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613130882072
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.to_csv('comments_tokens_2020_12.txt',sep ='\\t',line_terminator='\\r\\n',index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613125859726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f.to_excel('vBanking_tokens_s.xlsx',index = False)\n",
        "#df_f[df_f['value']>0].to_excel('D://Downloads//comments_tokens.xlsx')\n",
        "#df.to_excel('D://Downloads//comments_cleaned.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1613125859909
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f[df_f['CON_ROW_ID'] ==60427536]\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613125860014
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}