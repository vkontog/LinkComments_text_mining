{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncommend and run the following pip & python commands when running a new compute for the <b> first</b> time! "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download el_core_news_sm\r\n",
        "#!pip install pyarrow --upgrade\r\n",
        "#!pip install openpyxl\r\n",
        "#!pip install xlrd"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889372535
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import el_core_news_sm\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1615889372811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import GreekLemmatizer"
      ],
      "outputs": [],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1615889372911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1615889373125
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp =spacy.load('el_core_news_sm', disable=['tagger', 'parser', 'ner'])\r\n"
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1615889373219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = GreekLemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1615889373437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = re.compile('δεν απαντ.{1,3}\\s{0,1}',re.IGNORECASE)\r\n",
        "p2 = re.compile('\\sδα\\s',re.IGNORECASE)\r\n",
        "p3 = re.compile('δε.{0,1}\\s.{0,3}\\s{0,1}βρ.{1,2}κ.\\s{0,1}',re.IGNORECASE)\r\n",
        "p4 = re.compile('[^\\d]?\\d{10}')\r\n",
        "p5 = re.compile('[^\\d]?\\d{18}|[^\\d]\\d{20}')\r\n",
        "p6 = re.compile('δε[ ν]{0,1} (επιθυμ[α-ω]{2,4}?|ηθελ[α-ω]{1,3}?|θελ[α-ω]{1,4}|.{0,10}ενδιαφερ[α-ω]{2,4})',re.IGNORECASE)\r\n",
        "p7 = re.compile('δε[ ν]{0,1} (μπορ[α-ω]{2,5}|.εχει)',re.IGNORECASE)"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889373740
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadStopWords():\n",
        "    sWords = open('stopWords.txt','r',encoding='utf-8')\n",
        "    sw = set(sWords.read().split('\\n'))\n",
        "    #sw = sw.remove('μη')\n",
        "    sWords.close()\n",
        "    return sw"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1615889373990
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTerm(text):\r\n",
        "    text = p5.sub(' λογαριασμός ',text)\r\n",
        "    text = p4.sub(' τηλεφωνο ',text)\r\n",
        "    text = p6.sub(' δενθελειδενενδιαφερεται ',text)\r\n",
        "    text = p7.sub(' δενεχειδενμπορει ',text)\r\n",
        "    text = text.replace('-banking','banking')\r\n",
        "    text = text.replace('v banking','vbanking')\r\n",
        "    text = text.replace('e banking','ebanking')\r\n",
        "    text = text.replace('follow up','followup')\r\n",
        "    text = text.replace('safe drive','safedrive')\r\n",
        "    text = text.replace('safe pocket','safepocket')\r\n",
        "    text = text.replace('sweet home','sweethome')\r\n",
        "    text = text.replace('credit card','creditcard')\r\n",
        "    text = text.replace('debit card','debitcard')\r\n",
        "    text = text.replace('life cycle','lifecycle')\r\n",
        "    text = text.replace('π/κ','πκ')\r\n",
        "    text = text.replace('td','πκ')\r\n",
        "    text = text.replace('α/κ','ακ')\r\n",
        "    text = text.replace('δ/α','δεναπαντα ')\r\n",
        "    #τδ\r\n",
        "    text = p1.sub(' δεναπαντα ',text)\r\n",
        "    text = p2.sub(' δεναπαντα ',text)\r\n",
        "    text = p3.sub(' δεντονβρηκα ',text)\r\n",
        "    return text\r\n"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889374359
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sw = nlp.Defaults.stop_words\n",
        "#sw = sw|{'εχω','απο','ωστε'}\n",
        "sw = loadStopWords()\n",
        "def remove_ton(text):\n",
        "    diction = {'ά':'α','έ':'ε','ί':'ι','ό':'ο','ώ':'ω','ύ':'υ'}\n",
        "    for key in diction.keys():\n",
        "        text = text.replace(key, diction[key])\n",
        "    return text   \n",
        "def clean_text(text):\n",
        "     #text to string\n",
        "    text = str(text).lower()\n",
        "    text = replaceTerm(text)\n",
        "    \n",
        "   # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # lower text\n",
        "    text = [remove_ton(x) for x in text]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in sw]\n",
        " \n",
        "    #remove quotes\n",
        "    text = [x.replace('quot;','').replace('&quot','') for x in text if x not in {'quot','amp'}]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # remove amp & quot\n",
        "    text = [x for x in text if x not in ['quot','amp']]\n",
        "    # remove words with only one letter\n",
        "    text = \" \".join([t for t in text if len(t) > 1])\n",
        "     # lemmatize text\n",
        "    text = \" \".join([lemmatizer(t.text,t.pos_)[0] for t in nlp(text)])\n",
        "   \n",
        "    return(text)"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1615889374631
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(x,corDict):\r\n",
        "    if x in corDict.keys():\r\n",
        "        y = corDict[x]\r\n",
        "    else:\r\n",
        "        y = x\r\n",
        "    return y    "
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889374742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams(idf,mindf,minngram,maxngram):\r\n",
        "    tfidf = TfidfVectorizer(min_df = mindf,ngram_range = (minngram,maxngram))\r\n",
        "    tfidf_result = tfidf.fit_transform(idf['tokenized']).toarray()\r\n",
        "    tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\r\n",
        "    tfidf_df.columns = [str(x) for x in tfidf_df.columns]\r\n",
        "    df_i = pd.concat([df[['CON_ROW_ID']],tfidf_df],axis=1).melt(id_vars=['CON_ROW_ID'],value_vars = tfidf_df.columns).dropna()\r\n",
        "    df_i = df_i[df_i['value']>0]\r\n",
        "    return df_i"
      ],
      "outputs": [],
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889375011
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanComments(df):\r\n",
        "    df = df[['CON_ROW_ID','CON_COMMENTS']]\r\n",
        "    df['tokenized'] = df['CON_COMMENTS'].apply(clean_text)\r\n",
        "    df = df.fillna('N/A')\r\n",
        "    df['variable'] = df['tokenized'].str.split()\r\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889375358
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getTokens(df):\r\n",
        "    df = cleanComments(df)\r\n",
        "    df_f = df.explode('variable')[['CON_ROW_ID','variable']]\r\n",
        "    return df_f\r\n"
      ],
      "outputs": [],
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889375456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getTokencount(df_f,minCount):\r\n",
        "    tokenCount = df_f['variable'].value_counts().to_dict()\r\n",
        "    df_f['value'] = df_f['variable'].map(tokenCount)\r\n",
        "    df_f=df_f[df_f['value']>minCount] \r\n",
        "    return df_f"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889375728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadComments(fileNum):\r\n",
        "    # azureml-core of version 1.0.72 or higher is required\r\n",
        "    # azureml-dataprep[pandas] of version 1.1.34 or higher is required\r\n",
        "    from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "    subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\r\n",
        "    resource_group = 'MLRG'\r\n",
        "    workspace_name = 'erbbimlws'\r\n",
        "\r\n",
        "    workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "    dataset = Dataset.get_by_name(workspace, name='LinkComments{0}'.format(fileNum))\r\n",
        "    df = dataset.to_pandas_dataframe()\r\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889375990
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileNum = '03'"
      ],
      "outputs": [],
      "execution_count": 90,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889376095
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = loadComments(fileNum)"
      ],
      "outputs": [],
      "execution_count": 91,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889377280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = cleanComments(df)"
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889458179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = getTokens(df)"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889298602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minCount = 100\r\n",
        "df_f = getTokencount(df_f,minCount)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889299305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrams parameters\r\n",
        "mindf,minngram,maxngram = 1000,2,3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889299493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.append(get_ngrams(df,mindf,minngram,maxngram ))\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889310233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_tokenCount = pd.read_excel('tokenlist.xlsx',engine='openpyxl')\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889310425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['variable'].value_counts().to_excel('tokenlist.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889310705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corDict = dict(pd.read_excel(\"corTokens.xls\").to_dict(\"split\")['data'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889310907
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token'] = df_f['variable'].apply(lambda x : correct(x,corDict))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889311339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['token'] !='rmv']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889311647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['token'].str.len() >1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889312098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f['token'].value_counts().to_excel('tokenlist.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889312279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889312494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.sort_values(['CON_ROW_ID','token'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889313051
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[['CON_ROW_ID','token']].drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889313472
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.to_csv('comments_tokens_2020_{0}.txt'.format(fileNum),sep ='\\t',line_terminator='\\r\\n',index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889316611
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f['token'].value_counts().to_excel('tokenlist_new.xlsx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889316791
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df\r\n",
        "#df[df.tokenized.str.contains('/')].count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615889316884
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}